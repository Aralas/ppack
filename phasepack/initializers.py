#!/usr/bin/python
# -*- coding: utf-8 -*-
""" File solvers.py

Last update: 15/08/2018

Usage:

"""
__version__ = "1.0.0"
__author__ = 'Juan M. Bujjamer'
__all__ = ['solvePhaseRetrieval']

import numpy as np
from numpy.linalg import norm
from scipy.sparse.linalg import eigs
from phasepack.util import Options

from phasepack.util import ConvMatrix


def  initSpectral(A, b0, n, At=None, isScaled=False, isTruncated=False, verbose=False):
    """ Intializer proposed in Algorithm 1 of the Wirtinger Flow paper.

    This initializer forms a matrix from the data and computes the largest eigenvector that is shown to be positively correlated with the unknown true signal. This script presents both the vanilla spectral method and the truncated spectral method. A recently proposed 'optimal' spectral initializer method was proposed and is presented in a different file.
     Inputs:
        A:  m x n matrix (or optionally a function handle to a method) that returns A*x.
        At: The adjoint (transpose) of 'A'. If 'A' is a function handle, 'At' must be provided.
        b0: m x 1 real, non-negative vector consists of all the measurements.
        n:  The size of the unknown signal. It must be provided if A is a function handle.
        isTruncated (boolean): If true, use the 'truncated' initializer that uses a sub-sample of the measurement.
        isScaled (boolean):    If true, use a least-squares method to determine  the optimal scale of the initializer.

        Note: When a function handle is used, the value of 'n' (the length of the unknown signal) and 'At' (a function handle for the adjoint of 'A') must be supplied.  When 'A' is numeric, the values of 'At' and 'n' are ignored and inferred from the arguments.

     Outputs:
        x0:  A n x 1 vector. It is the guess generated by the spectral method for  the unknown signal.

     See the script 'testInitSpectral.m' for an example of proper usage of this function.

    % Notations
     Our notations follow the TWF paper.
     ai is the conjugate transpose of the ith row of A.
     yi is the ith element of y, which is the element-wise square of the
     measurements b0.

    % Algorithm Description
     The method has two steps
     (1) If isTruncated==true, Discard those observations yi that are
         several times greater than the mean during spectral initialization.
     (2) Calculate the leading eigenvector of a matrix Y,
         where Y = 1/m sum(yi * ai * ai') for i = 1 to m.
     The method return this leading eigenvector, which is calcualted using
     Matlab's eigs() routine. Note: The truncation, when used, makes the
     method more robust to outliers and performs better in practice.

     For a detailed explanation, see Algorithm 1 in the TWF paper referenced
     below.

     Note:
     The papers below recommend using the power method to compute the leading
     eigenvector.  Our implemention uses Matlab's built-in function eigs()
     to get the leading eigenvector because of greater efficiency.

    % References
     For spectral method
     Paper Title:   Phase Retrieval via Wirtinger Flow: Theory and Algorithms
     Place:         Algorithm 1
     Authors:       Emmanuel Candes, Xiaodong Li, Mahdi Soltanolkotabi
     Arxiv Address: https://arxiv.org/abs/1407.1065

     For truncated spectral method
     Paper Title:   Solving Random Quadratic Systems of Equations Is Nearly as
                    Easy as Solving Linear Systems
     Place:         Algorithm 1
     Authors:       Yuxin Chen, Emmanuel J. Candes
     Arxiv Address: https://arxiv.org/abs/1505.05114

    PhasePack by Rohan Chandra, Ziyuan Zhong, Justin Hontz, Val McCulloch,
    Christoph Studer, & Tom Goldstein
    Copyright (c) University of Maryland, 2017
    """

    # if  type(A) == np.ndarray:
    #     n = Am.shape[1]
    #     # Transform matrix into function form
    #     At = lambda x: Am.T@x
    #     A = lambda x: Am@x

    m = b0.size  # number of measurements
    if verbose:
        print('Estimating signal of length %d using a spectral initializer\
              with %d measurements...' % (n, m))

    # Truncated Wirtinger flow initialization
    alphay = 3                      # (4 also works fine)
    y = b0**2                       # To be consistent with the notation in the TWF paper Algorithm 1.
    lambda0 = np.sqrt(1/m*sum(y))   # Defined in the TWF paper Algorithm 1
    idx = np.ones((b0.size, 1))         # Indices of observations yi
    # Truncate indices if isTruncated is true
    # It discards those observations yi that are several times greater than
    # the mean during spectral initialization.
    if isTruncated:
        idx = np.abs(y)<=alphay**2*lambda0**2

    # Build the function handle associated to the matrix Y
    # in the TWF paper Algorithm 1
    # Yfunc = lambda x : 1/m*At((idx.*b0.^2).*A(x))
    # Ymat = 1/m*At@((idx*b0**2)*A)
    # # Y = 1/m*At.product()
    # # Our implemention uses Matlab's built-in function eigs() to get the leading
    # # eigenvector because of greater efficiency.
    # # Create opts struct for eigs
    # # Get the eigenvector that corresponds to the largest eigenvalue of the
    # # associated matrix of Yfunc.
    # [eval, x0] = eigs(Ymat, k=1, which='LR')
    [eval, x0] = A.calc_yeigs(m, b0, idx)
    # This part does not appear in the paper. We add it for better
    # performance. Rescale the solution to have approximately the correct
    # magnitude
    if isScaled:
        # Pick measurements according to the indices selected
        b = b0*idx
        Ax = np.abs(A*x0)*idx
        # solve min_s || s|Ax| - b ||
        u = Ax*b
        l = Ax*Ax
        s = norm(u)/norm(l)
        x0 = x0*s  # Rescale the estimation of x

    if verbose:
        print('Initialization finished.')

    return x0

def initOptimalSpectral(A, b0, n, At=None, isScaled=False, isTruncated=False, verbose=False):
    """
    Optimal spectral initializer.

    Initializer recently proposed based on an optimal spectral method. The
    plain vanilla spectral initializer computes the largest eigenvector of Y
    = 1/m sum(yi * ai * ai') for i = 1 to m.  The truncated version of this
    method throws away some of the rows.  The optimal spectral nitializer
    computes the largest eigenvector of Y = 1/m sum(T(yi) * ai * ai') for i
    = 1 to m, where T(yi) is a function of yi given in equation (5) of the
    paper cited below.

    % I/O
     Inputs:
        A:  m x n matrix (or optionally a function handle to a method) that
            returns A*x.
        At: The adjoint (transpose) of 'A'. If 'A' is a function handle, 'At'
            must be provided.
        b0: m x 1 real,non-negative vector consists of all the measurements.
        n:  The size of the unknown signal. It must be provided if A is a
            function handle.
        isTruncated (boolean): If true, use the 'truncated' initializer that
                               uses a sub-sample of the measurement.
        isScaled (boolean):    If true, use a least-squares method to
                               determine  the optimal scale of the
                               initializer.

        Note: When a function handle is used, the value of 'n' (the length of
        the unknown signal) and 'At' (a function handle for the adjoint of
        'A') must be supplied.  When 'A' is numeric, the values of 'At' and
        'n' are ignored and inferred from the arguments.

     Outputs:
        x0:  A n x 1 vector. It is the guess generated by the spectral method
             for  the unknown signal.

     See the script 'testInitOptimalSpectral.m' for an example of proper usage of
     this function.

    % Notation
     Our notation follows the TWF paper.
     ai is the conjugate transpose of the ith row of A.
     yi is the ith element of y, which is the element-wise square of the
     measurements b0.

    % Algorithm Description.
     Calculate the leading eigenvector of a matrix Y, where Y = 1/m sum(T(yi)
     * ai * ai') for i = 1 to m, where T() is a "pre-processing" function.
     The method return this leading eigenvector,
     which is calculated using Matlab's eigs() routine.

     Note: This implementation differs from the paper in several ways that
     make it more efficient and robust.
     The papers below recommend using the power method to compute the leading
     eigenvector.  Our implemention
     uses Matlab's built-in function eigs() to get the leading eigenvector
     because of greater efficiency.

     Also, the authors define the pre-processing function
                    T(z) = (z-1)/(z+sqrt(delta)-1),
    where delta is the ratio of number of measurements to number of
    dimensions.  This formula assumes that the measurements are Gaussian with
    variance 1/n, and the unknown signal has length sqrt(n).  This assumption
    is clearly violated by most real sensing matrices and signals.  However,
    note that this measurements model yields measurements y = abs(Ax)^2 that
    have expected value E(y)=1.  For this reason, we normalize the
    measurements to have mean 1 before we apply the pre-processing function.
    We then multiply the mean back into the results when we're done
    pre-processing.

    % References
     Title:   Fundamental Limits of Weak Recovery with Applications to Phase
              Retrieval
     Place:   Equations (4) and (5)
     Authors: Marco Mondelli, Andrea Montanari
     Arxiv Address: https://arxiv.org/pdf/1708.05932.pdf

    PhasePack by Rohan Chandra, Ziyuan Zhong, Justin Hontz, Val McCulloch,
    Christoph Studer, & Tom Goldstein
    Copyright (c) University of Maryland, 2017
    """
    m = b0.size  # number of measurements

    if verbose:
        print('Estimating signal of length %d using the optimal spectral\
              initializer with %d measurements...' % (n, m))

    # Measurements as defined in the paper
    y = b0**2
    delta = m/n    # Used in equation (5) of paper

    # Normalize the measurements
    ymean = np.mean(y)
    y = y/ymean

    # Apply pre-processing function
    yplus = np.maximum(y, 0) # Element-wise max
    T = (yplus-1)/(yplus+np.sqrt(delta)-1)  # Formula from equation 25 in paper

    # Un-normalize the measurements
    T *= ymean

    idx = np.ones((b0.size, 1)) # Indices of observations yi
    # Our implemention uses Matlab's built-in function eigs() to get the leading
    # eigenvector because of greater efficiency.
    # Create opts struct for eigs
    # Yfunc = @(x) 1/m*At(T.*A(x));
    x0 = A.calc_yeigs(m, T, idx)
    if isScaled:
        # Pick measurements according to the indices selected
        b = b0
        Ax = np.abs(A*x0)
        # solve min_s || s|Ax| - b ||
        u = Ax*b
        l = Ax*Ax
        s = norm(u)/norm(l)
        x0 = x0*s  # Rescale the estimation of x
    if verbose:
        print('Initialization finished.')

    return x0
